%How can we concurrently visit multiple URLs and still be able to determine which URL was responsible for malicious activities?

%\item Which techniques are used by browsers to make concurrently visiting multiple URLs possible?
%\item Which APIs are used by web browsers to make HTTP requests and retrieve webpages?
%\item How can we link an HTTP request to its source URL without the modification of the used web browser?
%\item What extra information from the client's (running) machine can be used to augment the information gained from network traffic to make the tracking of malware to its source URL easier?

In this research project was focussed on the question how the detection of drive-by download infections of malware can be improved by the means of concurrently visitting multiple URLs and still be able to determine which URL was responsible for malicious activities. To reach this goal have four subquestions been formulated.

