As stated in the conclusion is in this project a generic algorithm and preliminary proof of concept developed. During this project have several challenges and opportunities been identified to further improve this system and make it usable to for a real world large-scale detection system that is able to give an early warning when a website starts to spread malware.

The first step would be to write analysis components to detect specific characteristics of certain groups of malware. For this proof of concept has only a very basic analyser been written to demonstrate the working and feasibility of the algorithm. While empiric observations during the development with websites that are spreading malware shows that it is able to detect the malicious behaviour of several malware families, it's nowhere a complete detection system.

A possible interesting subject for a further research project is to use machine-learning algorithms to detect the malicious behavor instead of the development of specialised analysis components. This way could by training the system with visiting known non-infected websites even future malware be detected that shows behavioral patterns not seen before.

Further effort should be invested in finding the optimal granularity of the produced graphs. In the current proof of concept are many of the low-level API events combined and grouped in high-level events that describe the performed action. While this greatly reduces the effort needed to analyse the graph, this poses the risk that that crucial information is missed. Malware developers aware of the system could develop by carefully analysing the analysis components sequences of API calls that confuse the algorithm and as such will not result in an event in the graph.

This confusion is a known issue and is already sometimes problematic in a normal situation as observed in the proof of concept. While the internal handles of the operating system are unique within a process, they are reused after closing. Concurrent events by multiple threads such as rapidly opening and closing of those handles can result in an out of order observation of events.

The exact nature of this has not been investigated further as it occurred only on a very small scale and not within the events required for the demonstration analysis component. This could be a side effect of the trade-off between performance and accuracy of the used sandbox or a more fundamental issue regarding the way such sandboxes monitor the used APIs.

This performance-accuracy trade-off is also something to consider while turning the proof of concept in a fully functioning system. While tracing all APIs combined with analysis components that are able to use this data should result in a 100\% detection rate, this will result in an impractical slow system. For the proof of concept the logging of many of the currently not used APIs has been disabled. A study to the behavor of malware should be done to get an optimal subset of APIs to trace.

In a study by X\cite{xxx}\todo{Citaat} about the detection of the sandboxes used for dynamic malware analysis became clear that those sandboxes are easy to detect. While malware could easily change its behaviour and as such make it hard to analyse, the detection of such behaviour by trace the involved API calls is enough for a positive malware detection.

While a high performance was not a goal during the development of the proof of concept, several optimisations have already been implemented and further optimisations identified. A major speed improvement could be gain when the processing and filtering of the event data was performed in real-time during the execution in the sandbox. In the current setup is all data stored inside the sandbox and after finishing transferred to the host for analysis. 

When real-time analysis is implemented there is also no need anymore to shutdown the used sandbox after a fixed amount of websites. In this setup a booted sandbox could be used until a malware infection is detected. In this way there is always a clean sandbox used without the overhead of preventative destroying and rebuilding it or the need to stop a sandbox because the data have to be transferred to the host for analysis.

The current implementation of the algorithm is also not able to make use of the multi-cpu, multi-core setups found in modern systems. The main flow makes use of a single thread and it should be feasible to split this up in multiple threads. As the data of every individual process is separately stored, it should not be very difficult to process the data of every process in its own thread.

Another improvement would be if tabbed browsing could be used instead of having to start a new web browser instance for every website to visit. Even more performance improvement can be gained if multiple websites can be visited within a single tab instance. The difficulty to implement this is that some browsers reuse tab processes after a tab is closed and it's very hard to detect when a tab navigates to the next website.

If the proof of concept is turned into a fully working system, the same techniques should be applied to build similar setups for different operating systems or with different webbrowsers. As malware regularly targets specific configurations \todo{Citaat?}, the system could otherwise miss such targeted attacks.

The algorithm and proof of concept are designed in such way that with as little effort as possible the support can be extended to different operating environments. When the used sandbox system has support for the targeted platform, the development of a parsing and interpretation layer of the low-level and mapping to the higher level events should be sufficient to integrate it in the system.

