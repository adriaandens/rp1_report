The growing importance and economic losses of malware resulted in many research projects in the last years. The detection and analysis of malware has been researched from several different angles \cite{auto_malware,Chang2013} and resulted in many proposed static and dynamic analysis techniques.

In 2013, Le et al. \cite{Le2013} presented a framework that describes the common stages and characteristics of a drive-by download attack. They described four stages from placing the malicious content on a webpage until the execution of the malicious activity.

In 2011, a paper from Canali et al. \cite{Canali2011} was released about the problematic performance of dynamic analysis and with a solution proposed in the form of ``Prophiler''. Prophiler is a filter that deploys static analysis techniques and that is able to reduce the load with more than 85\% compared to dynamic analysis. This with a comparable amount of false negatives.

In the same year Rajab et al. \cite{Rajab11trendsin} gave an overview of the trends regarding web malware detection and how the malware tries to circumvent the detection. This research focused on the advantages and disadvantages of four techniques: Virtual Machine honeypots, Browser Emulation honeypots, Classification based on Domain Reputation and Anti-Virus Engines.

A different approach is taken by Rossow \textit{et al.} \cite{Rossow2011}, Cortjens \textit{et al.} \cite{Cortjens2012} and Kinkhorst \textit{et al.} \cite{Kinkhorst2009}. They have focused during multiple research projects on the ability to detect and identify malware on the network layer.

The predecessor of NCSC-NL started in 2007 with the development of their own system, namely the Honeyspider network \cite{honeyspider}, for the dynamic analysis of websites. This system crawled the biggest and most important websites of the Netherlands on a daily base. The downside of this system is that it requires a lot of maintenance and hence it started to become outdated.


